# Online Mode Workflow - Runs every 10 minutes or manually
name: Online Mode ‚≠ï (AUTO)

concurrency:
  group: dd-scraper-online
  cancel-in-progress: true

on:
  # Scheduled run every 10 minutes
  schedule:
    - cron: "*/10 * * * *"

  # Manual trigger with options
  workflow_dispatch:
    inputs:
      max_profiles:
        description: "Max profiles to scrape (0 = All Users)"
        required: false
        default: "0"
        type: string
      batch_size:
        description: "Batch size for processing"
        required: false
        default: "50"
        type: string

jobs:
  scrape-online:
    runs-on: ubuntu-latest

    steps:
      # ============================================================
      # STEP 1: Checkout Repository
      # ============================================================
      - name: üì• Checkout Repository
        uses: actions/checkout@v4

      # ============================================================
      # STEP 2: Setup Python
      # ============================================================
      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      # ============================================================
      # STEP 3: Setup Chrome and ChromeDriver
      # ============================================================
      - name: üåê Setup Chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable

      - name: üîó Configure ChromeDriver
        run: |
          echo "CHROMEDRIVER_PATH=$(which chromedriver)" >> $GITHUB_ENV

      # ============================================================
      # STEP 4: Install Python Dependencies
      # ============================================================
      - name: üì¶ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # ============================================================
      # STEP 5: Prepare Google Credentials
      # ============================================================
      - name: üîê Prepare Google Credentials
        shell: bash
        env:
          GOOGLE_CREDENTIALS_JSON: ${{ secrets.GOOGLE_CREDENTIALS_JSON }}
        run: |
          python - <<'PY'
          import json, os
          raw = os.environ.get('GOOGLE_CREDENTIALS_JSON', '')
          if not raw:
              print("ERROR: GOOGLE_CREDENTIALS_JSON secret not set!")
              exit(1)
          data = json.loads(raw)
          pk = data.get('private_key')
          if isinstance(pk, str):
              data['private_key'] = pk.replace('\\n', '\n')
          with open('credentials.json', 'w', encoding='utf-8') as f:
              json.dump(data, f)
          print("‚úÖ Credentials file created")
          PY

      # ============================================================
      # STEP 6: Run Online Mode Scraper
      # ============================================================
      - name: üåê Run Online Mode Scraper
        env:
          # Primary Account
          DAMADAM_USERNAME: ${{ secrets.DAMADAM_USERNAME }}
          DAMADAM_PASSWORD: ${{ secrets.DAMADAM_PASSWORD }}

          # Backup Account (optional)
          DAMADAM_USERNAME_2: ${{ secrets.DAMADAM_USERNAME_2 || secrets.DAMADAM_USERNAME }}
          DAMADAM_PASSWORD_2: ${{ secrets.DAMADAM_PASSWORD_2 || secrets.DAMADAM_PASSWORD }}

          # Google Sheets Configuration
          GOOGLE_SHEET_URL: ${{ secrets.GOOGLE_SHEET_URL }}
          GOOGLE_CREDENTIALS_JSON: ${{ secrets.GOOGLE_CREDENTIALS_JSON }}
          GOOGLE_APPLICATION_CREDENTIALS: credentials.json

          # Run Configuration (limit to 30 for scheduled runs)
          MAX_PROFILES_PER_RUN: ${{ github.event.inputs.max_profiles || '0' }}
          BATCH_SIZE: ${{ github.event.inputs.batch_size || '50' }}
        run: |
          echo "üåê Starting Online Mode..."
          echo "Max Profiles: ${{ github.event.inputs.max_profiles || '0' }}"
          echo "Batch Size: ${{ github.event.inputs.batch_size || '50' }}"
          
          python main.py online \
            --max-profiles ${{ github.event.inputs.max_profiles || '0' }} \
            --batch-size ${{ github.event.inputs.batch_size || '50' }}

      # ============================================================
      # STEP 7: Upload Logs (Always run, even on failure)
      # ============================================================
      - name: üìä Upload Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: online-mode-logs-${{ github.run_number }}
          path: |
            logs/
            *.log
          if-no-files-found: ignore
          retention-days: 7
