# DamaDam Scraper v2.100.0.18 - Production Ready

![Python Version](https://img.shields.io/badge/python-3.9+-blue.svg)
[![Contact](https://img.shields.io/badge/contact-net2outlawzz@gmail.com-brightgreen)](mailto:net2outlawzz@gmail.com)
[![Social](https://img.shields.io/badge/social-@net2nadeem-blueviolet)](https://instagram.com/net2nadeem)

ğŸš€ **Complete automation bot for scraping DamaDam.pk user profiles** with enhanced UI, dual login system, and multi-mode operation.

---

## ğŸ¯ Phase Scope

### Phase 1 (Profiles) - Current Work

- âœ… This repo is currently focused on **Phase 1: Profiles scraping**.
- âœ… Both **Target** and **Online** modes are part of Phase 1.
- âœ… Output (sheet columns + values) must remain stable.

### Phase 2 (Posts) - Planned (Not Started)

- ğŸš« Phase 2 implementation is **not started yet**.
- ğŸš« We will only move to Phase 2 after Phase 1 is fully approved and locked.

## ğŸ¯ Phase 1 Status (Profile)

âœ… **DONE (Verified locally: online + target runs working)**

## ğŸ¯ What's New in v2.100.0.18 (Profile Phase DONE)

### âœ… Recent Phase 1 Improvements

- **Terminal header** now shows the correct version from `Config.SCRIPT_VERSION`.
- **Run summary** now includes Phase 2 eligibility counts: `READY` / `NOT ELIGIBLE`.
- **IMPORTANT EVENTS** section added at the end of a run to highlight key warnings/errors.
- **Duplicate visibility**: when a duplicate is updated, a note is added on the `DATETIME SCRAP` cell describing changed fields.
- **Duplicate diff ignore** updated to ignore `PHASE 2` changes (does not count as updated).

> Lock milestone target: **v2.100.1.00** (when Phase 1 is fully locked and frozen).

### âœ… Fixes

- **LAST POST + TIME** now fetched from public profile page when private profile has no preview.
- **POSTS count** improved with additional selector fallbacks.
- **Sheets** no longer writes inline "Before/Now" text into cells.
- **Mode Logs**: Online runs no longer show Target-mode banners.
- **Profiles header**: Column L shows **RUN MODE** (header display).
- **IMAGE**: Stores real profile photo URL when available (cloudfront/avatar image), not placeholder.
- **Sheets stability**: Header formatting now retries on API 429 (quota) like other writes.

## âœ… Project Rule (Must Follow)

- **Testing Rule:** Jab bhi koi change ho (bug fix / improvement), pehle local pe **max 3â€“4 profiles** run karke test karo.
  - Example:
    - `python main.py online --max-profiles 3`
    - `python main.py target --max-profiles 3`

---

## ğŸ§¾ Issue Workflow (Easy Way)

- **Step 1:** GitHub pe pehle **Issue create** karo (1 issue = 1 problem).
- **Step 2:** Issue mein clearly likho:
  - What is wrong (kya problem hai)
  - Expected output (kya hona chahiye)
  - Screenshot/logs (agar available)
- **Step 3:** Issues ko priority do:
  - High: scraping broken / data blank
  - Medium: UI/log improvements
  - Low: refactor/cleanup
- **Step 4:** Hum **1 issue at a time** fix karenge: implement â†’ test (3â€“4 profiles) â†’ push.

---

## ğŸ§‘â€ğŸ’» Single Person Maintenance (Best Practice)

- **Branch workflow:**
  - New fixes hamesha **temp branch** mein karo.
  - Test successful ho jaye, phir merge to `main`.
- **Daily routine (simple):**
  - Create/Update issue
  - Fix in branch
  - Test (max 3â€“4 profiles)
  - `git add .` â†’ `git commit -m "<message>"` â†’ `git push origin <branch>`
  - Merge after verified run

## ğŸ¯ What's New in v2.100.0.16

### ğŸš€ Improvements

- **Pending-only Target Selection:** Only rows with 'pending' in Col B are processed in Target mode; 'Error', 'Done', etc. are always skipped.
- **Literal Nickname Handling:** Nicknames (including @ and special characters) are used as-is for scraping and URLs. No modification.
- **Auto GitHub Workflow:** After every successful run, all files are committed and merged to `main` (or a branch) automatically.

---

## ğŸ¯ What's New in v2.100.0.15

### âœ… **FIXED Issues**

- âœ… **Missing Data Extraction**: Restored all working selectors
  - FOLLOWERS count now extracted correctly
  - POSTS count now extracted correctly
  - LAST POST and LAST POST TIME fully working
  - IMAGE (profile picture) extraction fixed
  - RURL (rank star) extraction restored
  - MEH (Mehfil) data extraction working
  
- âœ… **Column Management**
  - Removed INTRO column (Column L) as requested
  - Removed Dashboard state columns (L, M, N, O)
  
- âœ… **Font Formatting**
  - "Quantico" font now applied to **ALL rows** (not just headers)
  - Consistent formatting across all sheets
  
- âœ… **Enhanced Login System**
  - Cookie-based session persistence (local runs)
  - Automatic backup account failover
  - GitHub Actions compatibility (no cookies needed)
  
- âœ… **Beautiful Terminal UI**
  - Emojis and colors for better readability
  - Progress indicators with animations
  - Comprehensive summary reports
  
- âœ… **GitHub Workflows**
  - **Target Mode**: Manual trigger with options
  - **Online Mode**: Auto-scheduled every 15 minutes

---

## ğŸš€ Quick Start (5 Minutes)

### 1. Clone & Install

```bash
git clone https://github.com/net2t/DD-CMS-Final.git
cd DD-CMS-Final
pip install -r requirements.txt
```

### 2. Setup Credentials

**A. Create `.env` file:**

```bash
cp .env.example .env
```

**B. Edit `.env` with your credentials:**

```env
# Primary Account (Required)
DAMADAM_USERNAME=your_username
DAMADAM_PASSWORD=your_password

# Backup Account (Recommended - prevents blocking)
DAMADAM_USERNAME_2=backup_username
DAMADAM_PASSWORD_2=backup_password

# Google Sheets
GOOGLE_SHEET_URL=https://docs.google.com/spreadsheets/d/YOUR_SHEET_ID/edit
```

**C. Add Google Service Account:**

1. Download `credentials.json` from Google Cloud Console
2. Place it in the project root directory
3. Share your Google Sheet with the service account email

### 3. Run Locally

```bash
# Target Mode (from 'RunList' sheet)
python main.py target --max-profiles 10

# Online Mode (from online users)
python main.py online --max-profiles 20

# Unlimited (all pending targets)
python main.py target --max-profiles 0
```

---

## ğŸ“‹ Features

### ğŸ¯ **Multi-Mode Scraping**

- **Online Mode**: Scrapes currently online users (auto-scheduled every 15 min)
- **Target Mode**: Scrapes from 'RunList' sheet (auto-scheduled every 55 min + manual trigger)
- **Test Mode**: Quick testing with predefined profiles

### ğŸ” **Robust Authentication**

- Cookie-based session persistence (faster login)
- Dual account system with automatic failover
- Prevents account blocking from repeated logins
- GitHub Actions ready (no file persistence needed)

### ğŸ“Š **Smart Data Handling**

- Nickname-based duplicate detection
- Clean sheet updates (no inline "Before/Now" text in cells)
- Profile state tracking (ACTIVE, UNVERIFIED, BANNED, DEAD)
- Automatic sorting by scrape date

### ğŸ¨ **Modern Terminal UI**

- Rich color-coded output with emojis
- Progress bars with animations
- Comprehensive summary reports
- Beautiful formatted tables

### ğŸ›¡ï¸ **Resilient & Scalable**

- API rate limit handling with retries
- Session timeout recovery
- Minor HTML change tolerance
- Centralized configuration

---

## ğŸ”§ Configuration

### Environment Variables

| Variable | Required | Default | Description |
| --- | --- | --- | --- |
| `DAMADAM_USERNAME` | âœ… Yes | - | Primary DamaDam login username |
| `DAMADAM_PASSWORD` | âœ… Yes | - | Primary DamaDam login password |
| `DAMADAM_USERNAME_2` | âš ï¸ Recommended | - | Backup account username (prevents blocking) |
| `DAMADAM_PASSWORD_2` | âš ï¸ Recommended | - | Backup account password |
| `GOOGLE_SHEET_URL` | âœ… Yes | - | Your Google Sheet URL |
| `GOOGLE_CREDENTIALS_JSON` | No | - | (Optional) Raw JSON for GitHub Actions |
| `MAX_PROFILES_PER_RUN` | No | 0 | Max profiles per run (0 = unlimited) |
| `BATCH_SIZE` | No | 20 | Batch size for processing |

### Google Sheets Setup

**Required Sheets:**

1. **Profiles** - Main profile data storage
2. **RunList** - Queue for target mode
3. **OnlineLog** - Log of all users seen online
4. **Dashboard** - High-level run statistics
5. **Tags** (optional) - Tag-to-user mappings

**RunList Sheet Format:**

| Nickname | Status | Remarks | SKIP |
| --- | --- | --- | --- |
| user123 | âš¡ Pending | | |
| user456 | Done ğŸ’€ | Profile updated | YES |

---

## ğŸ¤– GitHub Actions Setup

### 1. Add Repository Secrets

Go to **Settings â†’ Secrets and variables â†’ Actions** and add:

- `DAMADAM_USERNAME` - Primary account username
- `DAMADAM_PASSWORD` - Primary account password
- `DAMADAM_USERNAME_2` - Backup account username *(recommended)*
- `DAMADAM_PASSWORD_2` - Backup account password *(recommended)*
- `GOOGLE_SHEET_URL` - Your Google Sheet URL
- `GOOGLE_CREDENTIALS_JSON` - Full JSON content of `credentials.json`

### 2. Workflows

#### **Target Mode (Manual)**

- Navigate to **Actions â†’ Target Mode Scraper**
- Click **Run workflow**
- Set options:
  - `max_profiles`: 0 = all pending, or specify number
  - `batch_size`: Processing batch size (default: 20)

#### **Online Mode (Automatic)**

- Runs every 15 minutes automatically
- Can also trigger manually for testing
- Recommended `max_profiles`: 20-50 (to avoid timeouts)

---

## ğŸ§  Note (Documentation)

- Har bug/feature ke liye **Issue create** karna best hai.
- Fix complete hone ke baad:
  - README + CHANGELOG update
  - Test run (3â€“4 profiles)
  - Push + merge

---

## ğŸ—ï¸ Project Architecture

```text
DD-CMS-Final/
â”œâ”€â”€ .github/workflows/          # GitHub Actions
â”‚   â”œâ”€â”€ scrape-target.yml      # Manual target mode
â”‚   â””â”€â”€ scrape-online.yml      # Scheduled online mode
â”œâ”€â”€ config/                     # Configuration files
â”‚   â”œâ”€â”€ config_common.py       # Main config (FIXED columns)
â”‚   â”œâ”€â”€ config_online.py       # Online mode config
â”‚   â”œâ”€â”€ config_target.py       # Target mode config
â”‚   â””â”€â”€ selectors.py           # CSS/XPath selectors
â”œâ”€â”€ core/                       # Core components
â”‚   â”œâ”€â”€ browser_manager.py     # Browser setup
â”‚   â”œâ”€â”€ login_manager.py       # Login with cookies (FIXED)
â”‚   â””â”€â”€ run_context.py         # Shared run state
â”œâ”€â”€ phases/                     # Scraping phases
â”‚   â”œâ”€â”€ phase_profile.py       # Profile phase orchestrator
â”‚   â””â”€â”€ profile/               # Profile scraping logic
â”‚       â”œâ”€â”€ online_mode.py     # Online mode runner
â”‚       â””â”€â”€ target_mode.py     # Target mode runner (FIXED)
â”œâ”€â”€ utils/                      # Utilities
â”‚   â”œâ”€â”€ sheets_manager.py      # Google Sheets (FIXED fonts)
â”‚   â”œâ”€â”€ ui.py                  # Terminal UI (ENHANCED)
â”‚   â””â”€â”€ url_builder.py         # URL construction
â”œâ”€â”€ main.py                     # Entry point
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

---

## ğŸ“Š Data Columns

**Fixed Column Order (INTRO removed):**

| # | Column | Description |
| --- | --- | --- |
| 0 | ID | User ID |
| 1 | NICK NAME | Nickname |
| 2 | TAGS | Tags from Tags sheet |
| 3 | CITY | City |
| 4 | GENDER | Male/Female |
| 5 | MARRIED | Yes/No |
| 6 | AGE | Age |
| 7 | JOINED | Join date |
| 8 | FOLLOWERS | Follower count (FIXED) |
| 9 | STATUS | Normal/Banned/Unverified |
| 10 | POSTS | Post count (FIXED) |
| 11 | SKIP/DEL | Online/Target (future: Skip/Del markers) |
| 12 | DATETIME SCRAP | Scrape timestamp |
| 13 | LAST POST | Last post text (FIXED) |
| 14 | LAST POST TIME | Last post time (FIXED) |
| 15 | IMAGE | Profile image URL (FIXED) |
| 16 | PROFILE LINK | Profile URL |
| 17 | POST URL | Public posts URL |
| 18 | RURL | Rank star image (FIXED) |
| 19-22 | MEH NAME/TYPE/LINK/DATE | Mehfil data (FIXED) |
| 23 | PROFILE_STATE | ACTIVE/UNVERIFIED/BANNED/DEAD |

---

## ğŸ¨ Terminal Output Examples

### Header

```text
================================================================================
ğŸš€ DamaDam Scraper - TARGET MODE ğŸš€
Version: v2.100.0.17
Powered by Selenium + Google Sheets
================================================================================
```

### During Run

```text
12:34:56 ğŸ” [LOGIN] Attempting cookie-based login...
12:34:58 âœ… [OK] Cookie login successful
12:35:00 ğŸ” [SCRAPING] Scraping: user123
12:35:02 âœ… [OK] user123: new
```

### Summary Report

```text
ğŸ“Š Scraping Run Summary
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Metric                 â”ƒ         Value â”ƒ   Status â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”©
â”‚ ğŸ¯ Mode                â”‚        TARGET â”‚          â”‚
â”‚ âœ… Successful          â”‚            45 â”‚       âœ… â”‚
â”‚ âŒ Failed              â”‚             2 â”‚       âŒ â”‚
â”‚ ğŸ†• New Profiles        â”‚            38 â”‚          â”‚
â”‚ ğŸ”„ Updated Profiles    â”‚             7 â”‚          â”‚
â”‚ â±ï¸ Duration            â”‚      3m 42s â”‚       âš¡ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Future Phases (Coming Soon)

The scraper is designed for easy extension:

- **Phase 2**: Posts scraping (individual posts)
- **Phase 3**: Comments scraping
- **Phase 4**: Mehfil (group) scraping
- **Phase 5**: Custom phases via JSON config

---

## ğŸ› Troubleshooting

### Missing Data in Sheets

- **Issue:** FOLLOWERS, POSTS, IMAGE, etc. showing blank
- **Solution:** âœ… **FIXED in v2.100.0.17** - Selectors + public-page last post fallback restored

### Cookie Login Fails

- **Issue:** "Cookie login failed" message
- **Solution:** Delete `damadam_cookies.pkl` and run again. Fresh login will create new cookies.

### GitHub Actions Rate Limits

- **Issue:** API quota exceeded errors
- **Solution:** Reduce `max_profiles` or increase delay in config:

```python
SHEET_WRITE_DELAY = 2.0  # Increase from 1.0
```

### Account Blocked Warning

**Issue**: "Too many login attempts"

**Solution**: âœ… Use backup account (set `DAMADAM_USERNAME_2` and `DAMADAM_PASSWORD_2`)

---

## âœ¨ Credits

**Developed by:**

- **Author**: Nadeem
  - **Email**: `net2outlawzz@gmail.com`
  - **Social**: `@net2nadeem` (Instagram, Facebook)
- **AI Pair Programmer**: Claude (Anthropic)

---

## ğŸ“„ License

This project is for educational purposes only. Please respect the website's terms of service.

---

## ğŸ†˜ Support

For issues, questions, or feature requests:

- **Email**: <net2outlawzz@gmail.com>
- **Instagram**: @net2nadeem
- **Issues**: [GitHub Issues](https://github.com/net2t/DD-CMS-Final/issues)

---

**Happy Scraping! ğŸš€**
